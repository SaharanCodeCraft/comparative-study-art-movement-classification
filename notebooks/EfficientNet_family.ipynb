{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9c127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad65bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# For deterministic behavior (slightly slower, but safer)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa21d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ad2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = r\"C:\\Users\\ADMIN\\Documents\\AM Project\\Pandora_18k - AM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f980ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ba05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 11\n",
      "Class names: ['02_Early_Renaissance', '03_Northern_Renaissance', '04_High_Renaissance', '05_Baroque', '08_Realism', '09_Impressionism', '10_Post_Impressionism', '11_Expressionism', '13_Fauvism', '14_Cubism', '16_AbstractArt']\n"
     ]
    }
   ],
   "source": [
    "full_dataset = datasets.ImageFolder(\n",
    "    root=DATASET_ROOT,\n",
    "    transform=train_transform  # temporary; val transform applied later\n",
    ")\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class names:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31e0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 11035\n",
      "Training images: 8828\n",
      "Validation images: 2207\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# Important: assign correct transform to validation set\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "print(f\"Total images: {dataset_size}\")\n",
    "print(f\"Training images: {train_size}\")\n",
    "print(f\"Validation images: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f86ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776d3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    efficientnet_b0,\n",
    "    efficientnet_b1,\n",
    "    efficientnet_b2,\n",
    "    efficientnet_b3,\n",
    "    efficientnet_b4,\n",
    "    efficientnet_b5,\n",
    "    efficientnet_b6,\n",
    "    efficientnet_b7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aed05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFFICIENTNET_MODELS = {\n",
    "    \"b0\": efficientnet_b0,\n",
    "    \"b1\": efficientnet_b1,\n",
    "    \"b2\": efficientnet_b2,\n",
    "    \"b3\": efficientnet_b3,\n",
    "    \"b4\": efficientnet_b4,\n",
    "    \"b5\": efficientnet_b5,\n",
    "    \"b6\": efficientnet_b6,\n",
    "    \"b7\": efficientnet_b7,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e287080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet(model_name, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a pretrained EfficientNet model with a custom classifier head.\n",
    "    Backbone is frozen for baseline experiments.\n",
    "    \"\"\"\n",
    "    if model_name not in EFFICIENTNET_MODELS:\n",
    "        raise ValueError(f\"Invalid EfficientNet variant: {model_name}\")\n",
    "\n",
    "    # Load pretrained model\n",
    "    model = EFFICIENTNET_MODELS[model_name](weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "    # Freeze all backbone parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace classifier head\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = torch.nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Move to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a57e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "test_model = build_efficientnet(\"b0\", num_classes)\n",
    "\n",
    "print(test_model.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9536c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 2\n",
      "Total params: 213\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.requires_grad for p in test_model.parameters())\n",
    "total_params = sum(1 for _ in test_model.parameters())\n",
    "\n",
    "print(f\"Trainable params: {trainable_params}\")\n",
    "print(f\"Total params: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc70511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048af75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / labels.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb7ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c556f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a72f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    num_epochs\n",
    "):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = validate_one_epoch(\n",
    "            model, val_loader, criterion\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f87c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feca93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_efficientnet(\"b0\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f115a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_dataloaders(batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4889eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# Loss\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy helper\n",
    "# -----------------------------\n",
    "def compute_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / labels.size(0)\n",
    "\n",
    "# -----------------------------\n",
    "# Train one epoch\n",
    "# -----------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# -----------------------------\n",
    "# Validate one epoch\n",
    "# -----------------------------\n",
    "def validate_one_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# -----------------------------\n",
    "# Full training loop\n",
    "# -----------------------------\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = validate_one_epoch(\n",
    "            model, val_loader, criterion\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    return history\n",
    "\n",
    "# -----------------------------\n",
    "# Optimizer (BASELINE)\n",
    "# -----------------------------\n",
    "def get_optimizer(model, lr=1e-3):\n",
    "    return torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=lr\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daea96ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_optimizer(model, lr=0.001)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad64b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d6a6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train Loss: 1.6256, Train Acc: 0.4400 | Val Loss: 1.3772, Val Acc: 0.5220\n",
      "Epoch [2/10] | Train Loss: 1.3423, Train Acc: 0.5249 | Val Loss: 1.3023, Val Acc: 0.5365\n",
      "Epoch [3/10] | Train Loss: 1.2735, Train Acc: 0.5510 | Val Loss: 1.2691, Val Acc: 0.5478\n",
      "Epoch [4/10] | Train Loss: 1.2283, Train Acc: 0.5632 | Val Loss: 1.2321, Val Acc: 0.5573\n",
      "Epoch [5/10] | Train Loss: 1.2111, Train Acc: 0.5684 | Val Loss: 1.2430, Val Acc: 0.5541\n",
      "Epoch [6/10] | Train Loss: 1.1943, Train Acc: 0.5735 | Val Loss: 1.2342, Val Acc: 0.5587\n",
      "Epoch [7/10] | Train Loss: 1.1713, Train Acc: 0.5768 | Val Loss: 1.2248, Val Acc: 0.5628\n",
      "Epoch [8/10] | Train Loss: 1.1601, Train Acc: 0.5880 | Val Loss: 1.2332, Val Acc: 0.5605\n",
      "Epoch [9/10] | Train Loss: 1.1674, Train Acc: 0.5819 | Val Loss: 1.2391, Val Acc: 0.5618\n",
      "Epoch [10/10] | Train Loss: 1.1594, Train Acc: 0.5836 | Val Loss: 1.2467, Val Acc: 0.5573\n"
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    num_epochs=NUM_EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87fef29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_RESULTS_DIR = r\"C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\"\n",
    "os.makedirs(BASE_RESULTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be27de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_MAP = {\n",
    "    \"b0\": 16,\n",
    "    \"b1\": 16,\n",
    "    \"b2\": 16,\n",
    "    \"b3\": 16,\n",
    "    \"b4\": 8,\n",
    "    \"b5\": 8,\n",
    "    \"b6\": 4,\n",
    "    \"b7\": 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7189ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9ab0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion_matrix(\n",
    "    model,\n",
    "    dataloader,\n",
    "    class_names,\n",
    "    save_path,\n",
    "    normalize=False\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        cmap=\"Blues\",\n",
    "        annot=False\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Normalized Confusion Matrix\" if normalize else \"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b7340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_curves(history, save_dir):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.savefig(os.path.join(save_dir, \"loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.savefig(os.path.join(save_dir, \"accuracy.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f58c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Training EfficientNet-B0 ==========\n",
      "Epoch [1/10] | Train Loss: 1.6216, Train Acc: 0.4414 | Val Loss: 1.3530, Val Acc: 0.5265\n",
      "Epoch [2/10] | Train Loss: 1.3444, Train Acc: 0.5280 | Val Loss: 1.2692, Val Acc: 0.5460\n",
      "Epoch [3/10] | Train Loss: 1.2699, Train Acc: 0.5490 | Val Loss: 1.2597, Val Acc: 0.5428\n",
      "Epoch [4/10] | Train Loss: 1.2328, Train Acc: 0.5587 | Val Loss: 1.2401, Val Acc: 0.5587\n",
      "Epoch [5/10] | Train Loss: 1.1944, Train Acc: 0.5757 | Val Loss: 1.2402, Val Acc: 0.5510\n",
      "Epoch [6/10] | Train Loss: 1.1928, Train Acc: 0.5726 | Val Loss: 1.2431, Val Acc: 0.5523\n",
      "Epoch [7/10] | Train Loss: 1.1776, Train Acc: 0.5780 | Val Loss: 1.2500, Val Acc: 0.5514\n",
      "Epoch [8/10] | Train Loss: 1.1761, Train Acc: 0.5732 | Val Loss: 1.2330, Val Acc: 0.5618\n",
      "Epoch [9/10] | Train Loss: 1.1593, Train Acc: 0.5853 | Val Loss: 1.2277, Val Acc: 0.5632\n",
      "Epoch [10/10] | Train Loss: 1.1537, Train Acc: 0.5881 | Val Loss: 1.2423, Val Acc: 0.5555\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B0\n",
      "\n",
      "========== Training EfficientNet-B1 ==========\n",
      "Epoch [1/10] | Train Loss: 1.5989, Train Acc: 0.4461 | Val Loss: 1.3707, Val Acc: 0.5093\n",
      "Epoch [2/10] | Train Loss: 1.3277, Train Acc: 0.5290 | Val Loss: 1.2896, Val Acc: 0.5338\n",
      "Epoch [3/10] | Train Loss: 1.2607, Train Acc: 0.5488 | Val Loss: 1.2440, Val Acc: 0.5492\n",
      "Epoch [4/10] | Train Loss: 1.2441, Train Acc: 0.5616 | Val Loss: 1.2852, Val Acc: 0.5410\n",
      "Epoch [5/10] | Train Loss: 1.2185, Train Acc: 0.5652 | Val Loss: 1.2598, Val Acc: 0.5469\n",
      "Epoch [6/10] | Train Loss: 1.1981, Train Acc: 0.5743 | Val Loss: 1.2502, Val Acc: 0.5492\n",
      "Epoch [7/10] | Train Loss: 1.1889, Train Acc: 0.5740 | Val Loss: 1.2488, Val Acc: 0.5505\n",
      "Epoch [8/10] | Train Loss: 1.1615, Train Acc: 0.5851 | Val Loss: 1.2482, Val Acc: 0.5496\n",
      "Epoch [9/10] | Train Loss: 1.1545, Train Acc: 0.5879 | Val Loss: 1.2309, Val Acc: 0.5483\n",
      "Epoch [10/10] | Train Loss: 1.1547, Train Acc: 0.5852 | Val Loss: 1.2586, Val Acc: 0.5537\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B1\n",
      "\n",
      "========== Training EfficientNet-B2 ==========\n",
      "Epoch [1/10] | Train Loss: 1.7144, Train Acc: 0.4095 | Val Loss: 1.4462, Val Acc: 0.5007\n",
      "Epoch [2/10] | Train Loss: 1.4169, Train Acc: 0.5058 | Val Loss: 1.3473, Val Acc: 0.5265\n",
      "Epoch [3/10] | Train Loss: 1.3496, Train Acc: 0.5206 | Val Loss: 1.3072, Val Acc: 0.5324\n",
      "Epoch [4/10] | Train Loss: 1.3427, Train Acc: 0.5170 | Val Loss: 1.3009, Val Acc: 0.5261\n",
      "Epoch [5/10] | Train Loss: 1.3116, Train Acc: 0.5334 | Val Loss: 1.2987, Val Acc: 0.5279\n",
      "Epoch [6/10] | Train Loss: 1.3139, Train Acc: 0.5301 | Val Loss: 1.2973, Val Acc: 0.5265\n",
      "Epoch [7/10] | Train Loss: 1.2909, Train Acc: 0.5378 | Val Loss: 1.2724, Val Acc: 0.5505\n",
      "Epoch [8/10] | Train Loss: 1.2795, Train Acc: 0.5399 | Val Loss: 1.2783, Val Acc: 0.5374\n",
      "Epoch [9/10] | Train Loss: 1.2902, Train Acc: 0.5402 | Val Loss: 1.3019, Val Acc: 0.5342\n",
      "Epoch [10/10] | Train Loss: 1.2828, Train Acc: 0.5430 | Val Loss: 1.2885, Val Acc: 0.5387\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B2\n",
      "\n",
      "========== Training EfficientNet-B3 ==========\n",
      "Epoch [1/10] | Train Loss: 1.6867, Train Acc: 0.4223 | Val Loss: 1.4593, Val Acc: 0.4989\n",
      "Epoch [2/10] | Train Loss: 1.3882, Train Acc: 0.5097 | Val Loss: 1.3432, Val Acc: 0.5261\n",
      "Epoch [3/10] | Train Loss: 1.3213, Train Acc: 0.5273 | Val Loss: 1.3204, Val Acc: 0.5238\n",
      "Epoch [4/10] | Train Loss: 1.2936, Train Acc: 0.5340 | Val Loss: 1.2961, Val Acc: 0.5324\n",
      "Epoch [5/10] | Train Loss: 1.2583, Train Acc: 0.5443 | Val Loss: 1.2909, Val Acc: 0.5292\n",
      "Epoch [6/10] | Train Loss: 1.2647, Train Acc: 0.5466 | Val Loss: 1.3104, Val Acc: 0.5310\n",
      "Epoch [7/10] | Train Loss: 1.2503, Train Acc: 0.5470 | Val Loss: 1.2994, Val Acc: 0.5233\n",
      "Epoch [8/10] | Train Loss: 1.2387, Train Acc: 0.5532 | Val Loss: 1.3116, Val Acc: 0.5310\n",
      "Epoch [9/10] | Train Loss: 1.2253, Train Acc: 0.5604 | Val Loss: 1.3418, Val Acc: 0.5374\n",
      "Epoch [10/10] | Train Loss: 1.2425, Train Acc: 0.5557 | Val Loss: 1.2847, Val Acc: 0.5356\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B3\n",
      "\n",
      "========== Training EfficientNet-B4 ==========\n",
      "Epoch [1/10] | Train Loss: 1.7826, Train Acc: 0.3948 | Val Loss: 1.5247, Val Acc: 0.5043\n",
      "Epoch [2/10] | Train Loss: 1.4907, Train Acc: 0.4735 | Val Loss: 1.4047, Val Acc: 0.5134\n",
      "Epoch [3/10] | Train Loss: 1.4196, Train Acc: 0.4958 | Val Loss: 1.3641, Val Acc: 0.5161\n",
      "Epoch [4/10] | Train Loss: 1.3864, Train Acc: 0.5075 | Val Loss: 1.3336, Val Acc: 0.5356\n",
      "Epoch [5/10] | Train Loss: 1.3521, Train Acc: 0.5189 | Val Loss: 1.3248, Val Acc: 0.5401\n",
      "Epoch [6/10] | Train Loss: 1.3518, Train Acc: 0.5156 | Val Loss: 1.3114, Val Acc: 0.5446\n",
      "Epoch [7/10] | Train Loss: 1.3358, Train Acc: 0.5249 | Val Loss: 1.3118, Val Acc: 0.5324\n",
      "Epoch [8/10] | Train Loss: 1.3161, Train Acc: 0.5257 | Val Loss: 1.3066, Val Acc: 0.5247\n",
      "Epoch [9/10] | Train Loss: 1.3058, Train Acc: 0.5341 | Val Loss: 1.2971, Val Acc: 0.5378\n",
      "Epoch [10/10] | Train Loss: 1.3204, Train Acc: 0.5270 | Val Loss: 1.2986, Val Acc: 0.5347\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B4\n",
      "\n",
      "========== Training EfficientNet-B5 ==========\n",
      "Epoch [1/10] | Train Loss: 1.8081, Train Acc: 0.3667 | Val Loss: 1.6964, Val Acc: 0.4128\n",
      "Epoch [2/10] | Train Loss: 1.6031, Train Acc: 0.4335 | Val Loss: 1.6269, Val Acc: 0.4354\n",
      "Epoch [3/10] | Train Loss: 1.5704, Train Acc: 0.4388 | Val Loss: 1.5852, Val Acc: 0.4558\n",
      "Epoch [4/10] | Train Loss: 1.5386, Train Acc: 0.4631 | Val Loss: 1.5789, Val Acc: 0.4495\n",
      "Epoch [5/10] | Train Loss: 1.5494, Train Acc: 0.4556 | Val Loss: 1.5677, Val Acc: 0.4422\n",
      "Epoch [6/10] | Train Loss: 1.5459, Train Acc: 0.4616 | Val Loss: 1.5777, Val Acc: 0.4359\n",
      "Epoch [7/10] | Train Loss: 1.5374, Train Acc: 0.4584 | Val Loss: 1.5478, Val Acc: 0.4558\n",
      "Epoch [8/10] | Train Loss: 1.5481, Train Acc: 0.4576 | Val Loss: 1.5620, Val Acc: 0.4490\n",
      "Epoch [9/10] | Train Loss: 1.5320, Train Acc: 0.4602 | Val Loss: 1.5416, Val Acc: 0.4631\n",
      "Epoch [10/10] | Train Loss: 1.5149, Train Acc: 0.4650 | Val Loss: 1.5311, Val Acc: 0.4631\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B5\n",
      "\n",
      "========== Training EfficientNet-B6 ==========\n",
      "Epoch [1/10] | Train Loss: 1.9000, Train Acc: 0.3330 | Val Loss: 1.8439, Val Acc: 0.3362\n",
      "Epoch [2/10] | Train Loss: 1.7892, Train Acc: 0.3745 | Val Loss: 1.7625, Val Acc: 0.3684\n",
      "Epoch [3/10] | Train Loss: 1.7762, Train Acc: 0.3796 | Val Loss: 1.7378, Val Acc: 0.3883\n",
      "Epoch [4/10] | Train Loss: 1.7650, Train Acc: 0.3911 | Val Loss: 1.7787, Val Acc: 0.3570\n",
      "Epoch [5/10] | Train Loss: 1.7820, Train Acc: 0.3856 | Val Loss: 1.7596, Val Acc: 0.3620\n",
      "Epoch [6/10] | Train Loss: 1.7822, Train Acc: 0.3883 | Val Loss: 1.7259, Val Acc: 0.3883\n",
      "Epoch [7/10] | Train Loss: 1.7759, Train Acc: 0.3883 | Val Loss: 1.7087, Val Acc: 0.3942\n",
      "Epoch [8/10] | Train Loss: 1.7972, Train Acc: 0.3855 | Val Loss: 1.7807, Val Acc: 0.3620\n",
      "Epoch [9/10] | Train Loss: 1.7761, Train Acc: 0.3947 | Val Loss: 1.7741, Val Acc: 0.3620\n",
      "Epoch [10/10] | Train Loss: 1.7763, Train Acc: 0.3934 | Val Loss: 1.6938, Val Acc: 0.3933\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B6\n",
      "\n",
      "========== Training EfficientNet-B7 ==========\n",
      "Epoch [1/10] | Train Loss: 1.8946, Train Acc: 0.3398 | Val Loss: 1.7884, Val Acc: 0.3675\n",
      "Epoch [2/10] | Train Loss: 1.7736, Train Acc: 0.3851 | Val Loss: 1.7569, Val Acc: 0.3702\n",
      "Epoch [3/10] | Train Loss: 1.7697, Train Acc: 0.3896 | Val Loss: 1.7620, Val Acc: 0.3743\n",
      "Epoch [4/10] | Train Loss: 1.7445, Train Acc: 0.4000 | Val Loss: 1.7449, Val Acc: 0.3711\n",
      "Epoch [5/10] | Train Loss: 1.7574, Train Acc: 0.3945 | Val Loss: 1.6868, Val Acc: 0.3983\n",
      "Epoch [6/10] | Train Loss: 1.7665, Train Acc: 0.3873 | Val Loss: 1.7045, Val Acc: 0.3879\n",
      "Epoch [7/10] | Train Loss: 1.7733, Train Acc: 0.3992 | Val Loss: 1.6929, Val Acc: 0.4010\n",
      "Epoch [8/10] | Train Loss: 1.7402, Train Acc: 0.4156 | Val Loss: 1.6983, Val Acc: 0.3987\n",
      "Epoch [9/10] | Train Loss: 1.7649, Train Acc: 0.4013 | Val Loss: 1.6879, Val Acc: 0.3919\n",
      "Epoch [10/10] | Train Loss: 1.7680, Train Acc: 0.4031 | Val Loss: 1.7153, Val Acc: 0.3888\n",
      "Saved results to C:\\Users\\ADMIN\\Documents\\AM Project\\comparative-study-art-movement-classification\\results\\efficientnet_family\\B7\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "for model_name in EFFICIENTNET_MODELS.keys():\n",
    "    print(f\"\\n========== Training EfficientNet-{model_name.upper()} ==========\")\n",
    "\n",
    "    # Create model-specific result directory\n",
    "    model_dir = os.path.join(BASE_RESULTS_DIR, f\"B{model_name[-1]}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Build model\n",
    "    model = build_efficientnet(model_name, num_classes)\n",
    "\n",
    "    # DataLoaders\n",
    "    batch_size = BATCH_SIZE_MAP[model_name]\n",
    "    train_loader, val_loader = get_dataloaders(batch_size)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = get_optimizer(model, lr=LR)\n",
    "\n",
    "    # Train\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        num_epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(model_dir, \"best_model.pth\")\n",
    "    )\n",
    "\n",
    "    # Save curves\n",
    "    plot_and_save_curves(history, model_dir)\n",
    "\n",
    "    # Confusion matrices\n",
    "    plot_and_save_confusion_matrix(\n",
    "        model,\n",
    "        val_loader,\n",
    "        class_names,\n",
    "        os.path.join(model_dir, \"confusion_matrix.png\"),\n",
    "        normalize=False\n",
    "    )\n",
    "\n",
    "    plot_and_save_confusion_matrix(\n",
    "        model,\n",
    "        val_loader,\n",
    "        class_names,\n",
    "        os.path.join(model_dir, \"confusion_matrix_normalized.png\"),\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    print(f\"Saved results to {model_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
